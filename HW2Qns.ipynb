{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2Qns.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdVGS8oSjBkc"
      },
      "source": [
        "## EE 461P: Data Science Principles  \n",
        "### Assignment 2 \n",
        "### Total points: 60\n",
        "### Due: Thursday, Feb 25, 2021, submitted via Canvas by 11:59 pm  \n",
        "\n",
        "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UT eID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group. If you do change, let the TAs know.\n",
        "\n",
        "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)\n",
        "\n",
        "### Name(s) and EID(s):\n",
        "1. \n",
        "2. \n",
        "\n",
        "### Homework group No.: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFAfdc7iTrO7"
      },
      "source": [
        "# Question 1 - Cross Validation (15 pts)\n",
        "\n",
        "Use the given code below to load the dataset from \"data.csv\". The dataset contains eight attributes (or features, denoted by X1...X8) and two responses (or outcomes, denoted by y1 and y2). This dataset was created for energy analysis using 12 different building shapes.The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. By simulating various settings as functions of the afore-mentioned characteristics in total there are 768 building shapes. For more information on the dataset refer this [link](https://archive.ics.uci.edu/ml/datasets/Energy+efficiency). The aim is to use the eight features to predict one of the two responses.In this question, we will predict only the y1 response. \n",
        "\n",
        "Specifically:\n",
        "* X1 - Relative Compactness\n",
        "* X2 - Surface Area\n",
        "* X3 - Wall Area\n",
        "* X4 - Roof Area\n",
        "* X5 - Overall Height\n",
        "* X6 - Orientation\n",
        "* X7 - Glazing Area\n",
        "* X8 - Glazing Area Distribution\n",
        "* y1 - Heating Load\n",
        "* y2 - Cooling Load\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfGn68OdWQC_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import sklearn\n",
        "\n",
        "data = pd.read_csv(\"data_qn1.csv\",delimiter=\",\")\n",
        "y = data[\"Y1\"]\n",
        "X = data.drop(columns=[\"Y1\",\"Y2\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_2coqAWQZZ"
      },
      "source": [
        "\n",
        "We will be analyzing the following scenarios for the given dataset.\n",
        "\n",
        "* Compare hold-out(80:20) train-test split cross validation and K-Fold Cross Validation \n",
        "* What happens when the number of folds increase for K-Fold Cross Validation? \n",
        "* Variance in the prediction for each case - Hold Out Validation and K-Fold Validation?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te7QQxe4XEkh"
      },
      "source": [
        "\n",
        "a) [**3 pts**] Split the original dataset(X,y) into 80:20 [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) split, use linear regression to fit the model on the training data and evaluate the model using the test data. Report the root mean squared error (RMSE) on the test data for five different runs, make sure to store the RMSE values, we will use these values later to plot in part (d).\n",
        "\n",
        "b) [**3 pts**] Now, we will use [K-Fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) validation from sklearn to split the original data(X,y) into 5 folds. For each fold use linear regression to fit the model on training data and evaluate the model on the test data. Compute the average RMSE of the 5 folds, repeat the same for five different random splits of K-Fold. You can refer to the following line of code to perform the split. Make sure to vary the random_state value for five different runs. Record the RMSE values we will use them later in part (d).\n",
        "\n",
        "```\n",
        "kf = KFold(n_splits=5,random_state=random_state,shuffle=True)\n",
        "```\n",
        "\n",
        "c) [**3 pts**] Repeat the same experiment as in part (b) by varying the number of folds as k = 100,768 and record the RMSE for each value of k.\n",
        "\n",
        "d) [**3 pts**] Now, we will plot the box plot of the RMSE values obtained from part a), b) and c) together in a single figure. To reiterate, Hold out Validation(from part a) and k = 5, 100 and 768(part b and c) each with 5 values of RMSE for the 5 random states of the k-fold split. You can refer [here](https://matplotlib.org/stable/gallery/pyplots/boxplot_demo_pyplot.html#sphx-glr-gallery-pyplots-boxplot-demo-pyplot-py) on how to plot the boxplots. Boxplots are used to understand the variance in the values of the RMSE. For more information on box plots refer this [link](https://en.wikipedia.org/wiki/Box_plot). \n",
        "\n",
        "e) [**3 pts**] Using the boxplot answer the following questions,\n",
        "\n",
        "* What do you observe in the variation for RMSE of hold out validation and k-Fold validation, explain with reasoning which one will you choose to evaluate the model.\n",
        "\n",
        "* What happens when the number of folds increase to larger values?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NlllrWv2JMJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrn3rt3wzMv7"
      },
      "source": [
        "# Question 2 - Bias Variance TradeOff (10 pts)\n",
        "\n",
        "a) [**5pts**] What is the difference between the notion of model bias (for example, a model that predicts age as a function of some other features) and the bias of a point estimator (for example, the mean age of students estimated from a sample of age values)?\n",
        "\n",
        "b) [**5pts**] a) Assume you have a model trained to solve a problem. How do you expect (i) the bias and (ii) the variance to change if you used a larger training dataset, but no other process changed?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaPpQFaiB39a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT0qzWQHB4RT"
      },
      "source": [
        "# Question 3: Ridge and Lasso Regression (15 points)\n",
        "\n",
        "In this question you will explore the application of Lasso and Ridge regression using sklearn package in Python. Use the following code to load the train and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twwroG3-P4fi"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import warnings\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = pd.read_csv(\"data_qn3.csv\", index_col=0)\n",
        "df = df.loc[df['Year']==2014, :]\n",
        "df = df.drop('Year', axis=1)\n",
        "df = pd.get_dummies(df, columns=['Status'])\n",
        "df = df.dropna()\n",
        "\n",
        "# Creating training and testing dataset\n",
        "y = df.iloc[:, 0]\n",
        "X = df.iloc[:, 1:]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHdoWCdqQDHz"
      },
      "source": [
        "## Question 3.1 (3 points) \n",
        "Run Linear regression on the train dataset and print the $R^2$ value using the test dataset.\n",
        "\n",
        "## Question 3.2 (6 points) \n",
        "Run linear regression using Lasso and determine the value of $\\alpha$ that results in best test set performance. Consider `alphas=10**np.linspace(1,-2,100)*0.5`. Display the best value of $\\alpha$ as well as the corresponsing $R^2$ score on test set. Use the following parameters in Lasso model. Finally, store the best model separately. Also, use the co-efficients obtained and select the [columns with non-zero weights](https://stackoverflow.com/questions/62323713/selecting-columns-of-dataframe-where-lasso-coefficient-is-nonzero) and use them to create `X_train_lasso` and `X_test_lasso`. Show how many non-zero columns are present. Plot the coefficients of the lasso model for different alpha values, you can use log scale to plot the alphas in the x_axis.\n",
        "\n",
        "    copy_X=True\n",
        "    normalize=True # Normalizes data using StandardScaler()\n",
        "    random_state=42\n",
        "\n",
        "## Question 3.3 (6 points) \n",
        "Run linear regression using Ridge and determine the value of $\\alpha$ that results in best test set performance. Consider `alphas=10**np.linspace(1,-2,100)*0.5`. Display the best value of $\\alpha$ as well as the corresponsing $R^2$ score on test set. Use the following parameters in Ridge model.Plot the coefficients of the ridge model for different alpha values, you can use log scale to plot the alphas in the x_axis.\n",
        "\n",
        "    copy_X=True\n",
        "    normalize=True # Normalizes data using StandardScaler()\n",
        "    random_state=42\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzD571z_3hSz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzPjp2hd9qkH"
      },
      "source": [
        "# Question 4: Polynomial Feature Transformation (20 points) \n",
        "Often, you will find that transforming features into higher degrees will yield better models. In this question, we will see how to do non-linear regression using a linear model by using polynomial feature transformation. You will need to build only one plot for this entire question. So, plot everything on the same plot. Let us now consider the following dataset:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_jfDHNpL-0i"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "def h(x):\n",
        "    \"\"\" function to approximate by polynomial interpolation\"\"\"\n",
        "    return np.sin(x) + np.log(x) \n",
        "\n",
        "\n",
        "# generate points used to plot\n",
        "x_plot = np.linspace(2, 12, 100)\n",
        "\n",
        "# generate points and keep a subset of them\n",
        "x = np.linspace(2, 12, 100)\n",
        "\n",
        "rng = np.random.RandomState(20)\n",
        "rng.shuffle(x)\n",
        "\n",
        "x_train = np.sort(x[:50])\n",
        "x_test = np.sort(x[50:80])\n",
        "\n",
        "\n",
        "\n",
        "# create matrix versions of these arrays\n",
        "x_train = x_train[:, np.newaxis]\n",
        "x_test = x_test[:,np.newaxis]\n",
        "x_plot = x_plot[:, np.newaxis]\n",
        "\n",
        "y_train = h(x_train) + np.random.normal(0, 0.5, size=x_train.shape) \n",
        "y_test = h(x_test)+ np.random.normal(0, 0.5, size=x_test.shape) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoQFk35CL-Bl"
      },
      "source": [
        "1. Build a scatter plot with `s=30` and `marker='o'` using x_train and y_train. Also, build a line plot using `x_plot` and `h(x_plot)` to show the trend. (5 pts)\n",
        "2. Transform `x_train` and `x_test` using [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) with degrees 1,3,5,7,9,11 and save these transformed datasets. For example, if an input sample is two dimensional and of the form [$a$, $b$], the degree-2 polynomial features are [$1$, $a$, $b$, $a^2$, $ab$, $b^2$]. (5 pts)\n",
        "3. Use ridge regression with default parameters on each of these train datasets. Now, calculate the predicted target values for the fitted model using `.predict(X_plot)` and show line plots using `x_plot` and the predicted target values. Also, calculate the training MSE and test MSE for each of them using the model. (5 pts)\n",
        "4. Report your observations from the plot w.r.t how the evaluation metrics change on increasing the `degree` parameter. What do you think will happen if we keep on increasing the value of `degree`? (5 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMJ_ZadzRGkG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}